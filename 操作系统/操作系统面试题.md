### 操作系统的功能

1. 作业管理：包括任务、界面管理、人机交互、图形界面、语音控制和虚拟现实等；
2. 文件管理：又称为信息管理；
3. 存储管理：实质是对存储“空间”的管理，主要指对主存的管理；
4. 设备管理：实质是对硬件设备的管理，其中包括对输入输出设备的分配、启动、完成和回收；
5. 进程或处理机管理：实质上是对处理机执行“时间”的管理，即如何将CPU真正合理地分配给每个任务。

### 进程和线程的区别

一个程序至少有一个进程,一个进程至少有一个线程。进程是资源管理的最小单位，线程是程序执行的最小单位。

进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。

线程与进程的区别归纳：
a. 地址空间和其它资源：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。
b. 通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。
c. 调度和切换：线程上下文切换比进程上下文切换要快得多。  
d. 在多线程OS中，进程不是一个可执行的实体。

http://blog.jobbole.com/93386/

### 进程与线程的切换

进程切换分两步：

1.切换**页表**以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。

2.切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。同一个进程中的线程间进行切换，差不多仅需要切换线程的上下文(如寄存器状态等)。

### 进程间通信方式总结

- 管道

管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

流管道s_pipe: 去除了第一种限制,可以双向传输.

管道可用于具有亲缘关系进程间的通信，命名管道:name_pipe克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

- 信号量

信号量是一个**计数器**，可以用来控制多个进程对共享资源的访问。它常作为一种**锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

- 消息队列

消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

- 共享内存

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

- Socket

与其他通信机制不同的是，它可用于不同机器间的进程通信。

优缺点：

1. 管道：速度慢，容量有限，只有父子进程能通讯
2. Socket：任何进程间都能通讯，但速度慢
3. 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题
4. 信号量：不能传递复杂消息，只能用来同步
5. 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存


### 线程同步的方式

- 临界区

当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操 作共享资源的目的。 

- 事件

事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。

- 互斥量（Mutex）

互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，

但是更节省资源，更有效率。

- 信号量

当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。CSemaphore类对象保存了对当前访问某一个指定资源的线程的计数值，该计数值是当前还可以使用该资源的线程数目。

区别：

1. 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说Mutex可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。 
2. 互斥量（Mutex），信号量（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作

### 内核栈和用户栈

内核在创建进程的时候，在创建task_struct的同时，会为进程创建相应的堆栈。每个进程会有两个栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，cpu堆栈指针寄存器里面的内容是用户堆栈地址，使用用户栈；当进程在内核空间时，cpu堆栈指针寄存器里面的内容是内核栈空间地址，使用内核栈。

### 死锁

死锁：当一组进程中的每个进程都在等待对方释放资源而形成的僵局。

原因：

1. 资源不足
2. 资源获取顺序不对
3. 资源分配不当

必要条件：

1. 互斥
2. 不可剥夺
3. 请求和保持
4. 循环等待

策略：

1. 银行家算法
2. 一次性请求所有资源
3. 抢占
4. 资源排序

### 进程调度算法

1. 先来先服务
2. 短作业优先
3. 时间片轮转法
4. 高响应比优先

### 存储管理

- 页式

将进程空间和物理空间都划分成等大小的页块，可将内存中任意一块对应与进程空间的某一块页块，实现了离散分配和虚拟存储。使用页表来完成对进程空间与物理空间的地址映射。

页面置换算法：FIFO,LRU,OPT

- 段式

将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。

- 段页式

在段页式存储管理系统中，作业的地址空间首先被分成若干个逻辑分段，每段都有自己的段号，然后再将每段分成若干个大小相等的页。对于主存空间也分成大小相等的页，主存的分配以页为单位。段页式系统中，作业的地址结构包含三部分的内容：段号      页号      页内位移量。

页式管理的优点是没有外碎片，每个内碎片不超过页的大小。缺点是程序全部装入内存，要求有相应的硬件支持。 
段式管理优点是没有内碎片，可以分别编写和编译，可以针对不同类型的段采用不同的保护，可以按段为单位来进行共享，包括通过**动态链接进行代码共享**。缺点是会产生外碎片。 
段页式管理是段式管理与页式管理方案结合而成的所以具有他们两者的优点。但反过来说，由于管理软件的增加，复杂性和开销也就随之增加了。

### 虚拟存储

基于局部性原理，对程序部分装入内存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。

关键字：局部性原理，部分装入，缺失动态载入，动态淘汰。

局部性原理表现在以下两个方面：

- 时间局部性：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
- 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

实现技术：

- 请求分页存储管理。
- 请求分段存储管理。
- 请求段页式存储管理。

硬件支持：

- 一定容量的内存和外存。
- 页表机制（或段表机制），作为主要的数据结构。
- 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。
- 地址变换机构，逻辑地址到物理地址的变换。

### 操作系统的四大特征

- 并发
- 异步
- 共享
- 虚拟

http://www.cnblogs.com/zyf-zhaoyafei/p/4714598.html

http://www.jianshu.com/p/d254b138de03

### DMA

实现DMA传送的基本操作如下：

1、外设可通过DMA控制器**向CPU发出DMA请求**；
2、CPU响应DMA请求，系统转变为DMA工作方式，并把**总线控制权**交给DMA控制器；
3、由DMA控制器发送存储器地址，并决定传送数据块的长度；
4、执行DMA传送；DMA通过**窃取主存周期**完成和主存的数据交换。	
5、DMA操作结束，并把总线控制权交还CPU。

由于CPU根本不参加传送操作，因此就省去了CPU取指令、取数、送数等操作。在数据传送过程中，没有保存现场、恢复现场之类的工作。内存地址修改、传送字 个数的计数等等，也不是由软件实现，而是用硬件线路直接实现的。所以DMA方式能满足高速I/O设备的要求，也有利于CPU效率的发挥。

### 变量，常量，静态变量存储的位置

1、栈

由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。

2、堆

由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如果程序员没有释放掉，程序会一直占用内存，导致内存泄漏，在程序结束后，操作系统会自动回收。

3、自由存储区

由malloc等分配的内存块，它和堆是十分相似的，不过它是用free来释放分配的内存。

4、全局/静态存储区

全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。

5、常量存储区

这是一块比较特殊的存储区，他们里面存放的是常量

### 锁实现的底层原理

所谓的锁就是内存中一个整型数，拥有两种状态：空闲状态和上锁状态。加锁过程的伪代码：

```
int lock = read();
if (lock == LOCKED) return FAIL;
write(lock, LOCKED);
return SUCCESS;
```

从上面可以看出来，加锁的过程不是原子性的。

真正的原子操作必须由硬件提供支持，比如 x86 平台上如果在指令前面加上 “LOCK” 前缀，对应的机器码在执行时会把总线锁住，使得其他 CPU不能再执行相同操作，从而从硬件层面确保了操作的原子性。从硬件层面来看，CPU在执行加锁操作之前先执行关中断，在读取内存前需要锁住内存总线，更新锁的状态后释放内存总线和开中断。

```c++
struct lock {
    int locked;
    struct queue q;
    int sync;         /* Normally 0. */
};

void lock_acquire(struct lock *l) {
    Disable interrupts;
    while (aswap(&l->sync, 1) { // aswap: atomically read memory value and replace it with a given value: returns old value.
        /* Do nothing */
    }
    if (!l->locked) {
        l->locked = 1;
        l->sync = 0;
    } else {
        queue_add(&l->q, thread_current());
        l->sync = 0;
        thread_block();
    }
    Enable interrupts;
}

void lock_release(struct lock *l) {
    Disable interrupts;
    while (aswap(&l->sync, 1) {
        /* Do nothing */
    }
    if (queue_empty(&l->q) {
        l->locked = 0;
    } else {
        thread_unblock(queue_remove(&l->q));
    }
    l->sync = 0;
    Enable interrupts;
}
```

参考：

- [操作系统中锁的实现原理](http://blog.sina.com.cn/s/blog_75f0b54d0100r7af.html)
- [Implementing Locks](https://web.stanford.edu/class/cs140/cgi-bin/lecture.php?topic=lockImpl)

### 大小端问题

> **大端模式**，是指**数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中**，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放；
>
> **小端模式**，是指**数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中**，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低，和我们的逻辑方法一致。

应用场景：

1. 不同端模式的处理器进行数据传递时必须要考虑端模式的不同
2. 在网络上传输数据时，由于数据传输的两端对应不同的硬件平台，采用的存储字节顺序可能不一致。所以在TCP/IP协议规定了在网络上必须采用**网络字节顺序**，也就是**大端模式**。对于char型数据只占一个字节，无所谓大端和小端。而对于**非char类型数据**，必须在数据发送到网络上之前将其转换成大端模式。接收网络数据时按符合接受主机的环境接收。

